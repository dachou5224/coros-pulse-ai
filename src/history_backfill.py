import pandas as pd
import numpy as np
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime, timedelta
import os
import json
import time

# --- é…ç½® ---
JSON_KEY = os.getenv('GOOGLE_APPLICATION_CREDENTIALS_JSON')
SHEET_NAME = 'Coros_Running_Data'

def get_client():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    if not JSON_KEY:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° Google Credentials")
        return None
    try:
        creds_dict = json.loads(JSON_KEY)
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        return gspread.authorize(creds)
    except Exception as e:
        print(f"âŒ è®¤è¯å¤±è´¥: {e}")
        return None

def validate_settings(settings_df):
    try:
        if not pd.to_numeric(settings_df['Max HR'], errors='coerce').notnull().all(): return False
        if not pd.to_numeric(settings_df['Rest HR'], errors='coerce').notnull().all(): return False
    except: return False
    return True

def get_hr_params_vectorized(dates, settings_df):
    """
    âš¡ï¸ å‘é‡åŒ–åŠ é€Ÿç‰ˆå¿ƒç‡åŒ¹é…ï¼š
    ä¸å†ä¸€è¡Œè¡ŒæŸ¥ï¼Œè€Œæ˜¯åˆ©ç”¨ Pandas çš„ merge_asof å¿«é€ŸåŒ¹é…æœ€è¿‘çš„è®¾ç½®
    """
    # ç¡®ä¿éƒ½æŒ‰æ—¶é—´æ’åº
    dates = pd.DataFrame({'Date': dates}).sort_values('Date')
    settings = settings_df.sort_values('Date')
    
    # asof merge: æ‰¾åˆ° <= è·‘æ­¥æ—¥æœŸçš„æœ€è¿‘ä¸€æ¡è®¾ç½®
    merged = pd.merge_asof(dates, settings, on='Date', direction='backward')
    
    # å¦‚æœæœ‰äº›æ—©æœŸè·‘æ­¥æ—¥æœŸæ¯”ç¬¬ä¸€æ¡è®¾ç½®è¿˜æ—©ï¼Œå¡«å……ç¬¬ä¸€æ¡è®¾ç½®
    if merged['Max HR'].isnull().any():
        first_setting = settings.iloc[0]
        merged['Max HR'] = merged['Max HR'].fillna(first_setting['Max HR'])
        merged['Rest HR'] = merged['Rest HR'].fillna(first_setting['Rest HR'])
        
    return merged['Max HR'].values, merged['Rest HR'].values
# ... import éƒ¨åˆ†ä¿æŒä¸å˜ ...

def calculate_run_vdot(distance_km, duration_min):
    """
    ğŸ§ª æ ¸å¿ƒç®—æ³•ï¼šä¼°ç®—å•æ¬¡è·‘æ­¥çš„ VDOT
    é€»è¾‘ï¼šå…ˆåˆ©ç”¨ Riegel å…¬å¼å°†æœ¬æ¬¡è¡¨ç°å½’ä¸€åŒ–ä¸º "5km ç­‰æ•ˆæˆç»©"ï¼Œ
    å†åˆ©ç”¨ Daniels è¿‘ä¼¼å…¬å¼è®¡ç®— VDOTã€‚
    """
    # 1. è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼šè·ç¦»å¤ªçŸ­æˆ–å¤ªé•¿éƒ½ä¸å‡†ï¼Œé…é€Ÿå¤ªæ…¢ä¹Ÿä¸ç®—
    if distance_km < 3 or duration_min <= 0: return 0
    
    # 2. Riegel å…¬å¼å½’ä¸€åŒ–åˆ° 5km (é¢„æµ‹å°½åŠ›è·‘ 5km çš„ç”¨æ—¶)
    # T2 = T1 * (D2 / D1)^1.06
    # è¿™é‡Œçš„å‡è®¾æ˜¯ï¼šå¦‚æœä½ è¿™æ¬¡è·‘å¾—å¾ˆå¿«ï¼ŒRiegel ä¼šé¢„æµ‹å‡ºä¸€ä¸ªå¾ˆå¿«çš„ 5k
    # å¦‚æœä½ æ˜¯æ…¢è·‘ï¼Œé¢„æµ‹å‡ºçš„ 5k ä¹Ÿä¼šå¾ˆæ…¢ (VDOT å°±ä½) â€”â€” è¿™æ²¡å…³ç³»ï¼Œæˆ‘ä»¬åé¢åªå–æœ€å¤§å€¼
    predicted_5k_min = duration_min * (5 / distance_km) ** 1.06
    
    # 3. è®¡ç®— VDOT (åŸºäº 5km æˆç»©çš„å›å½’å…¬å¼)
    # é€Ÿåº¦ (ç±³/åˆ†)
    v = 5000 / predicted_5k_min
    
    # ä¸¹å°¼å°”æ–¯æ°§æ°”æˆæœ¬å…¬å¼ (Oxygen Cost)
    # VDOT ~= VO2max / drop_off_percent
    # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªé«˜ç²¾åº¦çš„æ‹Ÿåˆå…¬å¼ç›´æ¥ç®— VDOT
    # æ¥æºï¼šRunning formulas regression
    vdot = -4.6 + 0.182258 * v + 0.000104 * v**2
    
    return round(vdot, 1)

def get_current_vdot(df, end_date, window_days=42):
    """
    ğŸ“… è·å–æˆªæ­¢åˆ° end_date çš„â€˜å½“å‰è·‘åŠ›â€™
    é€»è¾‘ï¼šå›æº¯è¿‡å» window_days (é»˜è®¤6å‘¨) å†…æ‰€æœ‰è·‘æ­¥è®°å½•ï¼Œ
    å–å…¶ä¸­è®¡ç®—å‡ºçš„ã€æœ€å¤§ VDOT å€¼ã€‘ã€‚
    """
    start_date = end_date - timedelta(days=window_days)
    
    # ç­›é€‰æ—¶é—´çª—å£å†…çš„æ•°æ®
    mask = (df['Date'] >= start_date) & (df['Date'] <= end_date)
    window_df = df[mask]
    
    if window_df.empty:
        return 0
    
    # è®¡ç®—æ¯ä¸€å•çš„ VDOT
    vdot_values = []
    for _, row in window_df.iterrows():
        # å®¹é”™å¤„ç†
        try:
            d = float(row['Distance (km)'])
            t = float(row['Duration (min)'])
            v = calculate_run_vdot(d, t)
            if v > 0: vdot_values.append(v)
        except: continue
        
    if not vdot_values: return 0
    
    # å…³é”®ï¼šå–æœ€å¤§å€¼ (ä»£è¡¨ä½ çš„æ½œèƒ½ä¸Šé™)
    return max(vdot_values)

# ... main å‡½æ•° ...
def main():
    print("ğŸš€ å¯åŠ¨å†å²å‘¨æŠ¥å›æº¯ç”Ÿæˆå™¨ (History Backfill)...")
    client = get_client()
    if not client: return
    sh = client.open(SHEET_NAME)

    # 1. è¯»å–æ•°æ®
    print("ğŸ“¥ è¯»å–æ‰€æœ‰è¿åŠ¨æ•°æ®...")
    df = pd.DataFrame(sh.sheet1.get_all_records())
    if 'Activity ID' in df.columns:
         df['Activity ID'] = df['Activity ID'].astype(str)
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date')

    # 2. è¯»å–è®¾ç½®
    print("âš™ï¸ è¯»å–è®¾ç½®...")
    try:
        settings_ws = sh.worksheet('Settings')
        settings_df = pd.DataFrame(settings_ws.get_all_records())
        settings_df['Date'] = pd.to_datetime(settings_df['Date'], errors='coerce')
        settings_df = settings_df.dropna(subset=['Date']).sort_values('Date')
        if not validate_settings(settings_df): raise ValueError
    except:
        print("âš ï¸ ä½¿ç”¨é»˜è®¤å¿ƒç‡è®¾ç½®")
        settings_df = pd.DataFrame({'Date': [pd.Timestamp('2000-01-01')], 'Max HR': [185], 'Rest HR': [55]})

    # 3. æ‰¹é‡è®¡ç®— TRIMP
    print("ğŸ§® æ‰¹é‡è®¡ç®— TRIMP...")
    # æ¸…æ´—æ•°æ®
    df['Avg HR'] = pd.to_numeric(df['Avg HR'], errors='coerce').fillna(0)
    df['Duration (min)'] = pd.to_numeric(df['Duration (min)'], errors='coerce').fillna(0)
    
    # è·å–å¯¹åº”çš„ Max/Rest HR
    max_hrs, rest_hrs = get_hr_params_vectorized(df['Date'], settings_df)
    
    # å‘é‡åŒ–è®¡ç®—
    hrr = (df['Avg HR'] - rest_hrs) / (max_hrs - rest_hrs)
    hrr = hrr.clip(0, 1)
    weight = 0.64 * np.exp(1.92 * hrr)
    df['TRIMP'] = df['Duration (min)'] * hrr * weight
    df['TRIMP'] = df['TRIMP'].fillna(0).round(1)

    # 4. æ„å»ºæ¯æ—¥æ—¶é—´åºåˆ— (ä¸ºäº†è®¡ç®—è¿ç»­çš„ CTL/ATL)
    print("ğŸ“ˆ é‡å»ºæ¯æ—¥æ—¶é—´è½´ & è®¡ç®—çŠ¶æ€æŒ‡æ•°...")
    start_date = df['Date'].min().normalize()
    end_date = df['Date'].max().normalize()
    all_days = pd.date_range(start_date, end_date, freq='D')
    
    # æŒ‰å¤©æ±‡æ€» TRIMP (é˜²æ­¢ä¸€å¤©å¤šè·‘)
    daily_trimp = df.set_index('Date').resample('D')['TRIMP'].sum().reindex(all_days, fill_value=0)
    
    # è®¡ç®— CTL, ATL, TSB
    ctl = daily_trimp.ewm(span=42, adjust=False).mean()
    atl = daily_trimp.ewm(span=7, adjust=False).mean()
    tsb = ctl - atl
    
    # ç»„åˆæˆæ¯æ—¥çŠ¶æ€è¡¨
    daily_stats = pd.DataFrame({
        'TRIMP': daily_trimp,
        'CTL': ctl,
        'TSB': tsb
    })

    # 5. æŒ‰å‘¨é‡æ–°é‡‡æ · (Resample Weekly)
    # 'W-SUN' è¡¨ç¤ºæ¯èˆå…¥åˆ°å‘¨æ—¥ä½œä¸ºç»“æŸ
    # æ³¨æ„ï¼šæˆ‘ä»¬æƒ³è¦çš„æ˜¯ "ä¸Šå‘¨ä¸€åˆ°ä¸Šå‘¨æ—¥" çš„æ•°æ®ï¼Œè¿™é‡Œçš„é€»è¾‘æ˜¯ï¼š
    # è¿™ä¸€å‘¨çš„æ€»è·‘é‡ã€æ€»è´Ÿè·ï¼Œä»¥åŠè¿™ä¸€å‘¨ã€ç»“æŸæ—¶ã€‘çš„çŠ¶æ€(TSB)
    print("ğŸ“… æŒ‰å‘¨æ±‡æ€»æ•°æ®...")
    
    # è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—å¹³å‡é…é€Ÿ
    def avg_pace_calc(series):
        total_sec = 0
        count = 0
        for p_str in series:
            try:
                if isinstance(p_str, str) and "'" in p_str:
                    mins = int(p_str.split("'")[0])
                    secs = int(p_str.split("'")[1].replace('"',''))
                    total_sec += mins * 60 + secs
                    count += 1
            except: pass
        return total_sec / count if count > 0 else 0

    # èšåˆé€»è¾‘
    weekly_agg = df.set_index('Date').resample('W-SUN').agg({
        'Distance (km)': 'sum',
        'Activity ID': 'count', # æ¬¡æ•°
        'TRIMP': 'sum',
        'Avg Pace': avg_pace_calc # è‡ªå®šä¹‰èšåˆ
    })
    
    # æŠŠ TSB/CTL ä¹ŸæŒ‰å‘¨å–æ ·ï¼ˆå–æ¯å‘¨æ—¥çš„é‚£ä¸ªå€¼ï¼‰
    weekly_status = daily_stats.resample('W-SUN').last()
    
    # åˆå¹¶
    final_report = pd.concat([weekly_agg, weekly_status[['CTL', 'TSB']]], axis=1)
    
    # 6. å‡†å¤‡å†™å…¥æ•°æ®
    print("ğŸ“ å‡†å¤‡å†™å…¥æ•°æ®...")
    rows_to_write = []
    
    # ğŸ†• è¡¨å¤´å¢åŠ  VDOT
    headers = ["Week Start", "Week End", "Distance (km)", "Runs", "Avg Pace", "Weekly Load", "Fitness (CTL)", "Form (TSB)", "VDOT", "Status"]
    
    for date_idx, row in final_report.iterrows():
        # å¦‚æœè¿™ä¸€å‘¨æ²¡æœ‰ä»»ä½•æ•°æ®ä¸” TSB è¿˜æ²¡å»ºç«‹èµ·æ¥ï¼Œè·³è¿‡
        if row['Distance (km)'] == 0 and row['CTL'] < 1:
            continue
            
        week_end = date_idx
        week_start = week_end - timedelta(days=6)
        
        # ğŸ†• è®¡ç®—è¿™å‘¨ç»“æŸæ—¶çš„ VDOT (è¿‡å» 42 å¤©çª—å£)
        # è¿™é‡Œçš„ df æ˜¯å…¨å±€æ‰€æœ‰çš„åŸå§‹è·‘æ­¥æ•°æ®
        # æˆ‘ä»¬ä¼ å…¥ week_end ä½œä¸ºæˆªæ­¢æ—¶é—´ç‚¹
        current_vdot = get_current_vdot(df, week_end, window_days=42)
        
        # æ ¼å¼åŒ–é…é€Ÿ
        pace_sec = row['Avg Pace']
        pace_fmt = f"{int(pace_sec // 60)}'{int(pace_sec % 60):02d}\"" if pace_sec > 0 else "-"
        
        current_tsb = row['TSB']
        status_text = "æ¢å¤" if current_tsb > 10 else ("é€‚ä¸­" if current_tsb > -10 else "ç–²åŠ³")
        
        rows_to_write.append([
            week_start.strftime("%Y-%m-%d"),
            week_end.strftime("%Y-%m-%d"),
            round(row['Distance (km)'], 2),
            int(row['Activity ID']),
            pace_fmt,
            round(row['TRIMP']),
            round(row['CTL'], 1),
            round(row['TSB'], 1),
            current_vdot, # <--- å¡«å…¥æ•°æ®
            status_text
        ])

    # ... (å†™å…¥ Google Sheets ä¿æŒä¸å˜) ...

    # 7. å†™å…¥ Google Sheets
    # æ³¨æ„ï¼šè¿™æ¬¡æ˜¯å…¨é‡è¦†ç›–å†™å…¥ Weekly_Reportï¼Œé˜²æ­¢é‡å¤å’Œé¡ºåºæ··ä¹±
    try:
        try:
            report_ws = sh.worksheet('Weekly_Report')
            print("ğŸ§¹ æ¸…ç©ºæ—§çš„ Weekly_Report...")
            report_ws.clear()
        except:
            print("âœ¨ æ–°å»º Weekly_Report è¡¨...")
            report_ws = sh.add_worksheet(title="Weekly_Report", rows=len(rows_to_write)+20, cols=20)
            
        print(f"ğŸš€ æ­£åœ¨å†™å…¥ {len(rows_to_write)} å‘¨çš„å†å²æŠ¥å‘Š...")
        # åŠ ä¸Šè¡¨å¤´
        all_content = [headers] + rows_to_write
        report_ws.update(range_name='A1', values=all_content)
        print("âœ… å†å²å›æº¯å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ å†™å…¥å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
