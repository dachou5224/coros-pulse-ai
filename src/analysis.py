import pandas as pd
import numpy as np
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime, timedelta
import os
import json

# --- é…ç½® ---
# ç›´æ¥å¤ç”¨ç°æœ‰çš„ Secret
JSON_KEY = os.getenv('GOOGLE_APPLICATION_CREDENTIALS_JSON')
SHEET_NAME = 'Coros_Running_Data'

def get_client():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    if not JSON_KEY:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° Google Credentials Secret")
        return None
    
    # å…¼å®¹å¤„ç†ï¼šå¦‚æœæ˜¯ JSON å­—ç¬¦ä¸²ç›´æ¥åŠ è½½
    try:
        creds_dict = json.loads(JSON_KEY)
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        return gspread.authorize(creds)
    except Exception as e:
        print(f"âŒ è®¤è¯å¤±è´¥: {e}")
        return None

def validate_settings(settings_df):
    """ğŸ›¡ï¸ æ ¡éªŒ Settings è¡¨æ ¼æ•°æ®çš„åˆæ³•æ€§"""
    required_cols = ['Date', 'Max HR', 'Rest HR']
    # æ£€æŸ¥åˆ—åæ˜¯å¦å­˜åœ¨
    if not all(col in settings_df.columns for col in required_cols):
        print(f"âŒ Settings è¡¨ç¼ºå°‘åˆ—ï¼Œå¿…é¡»åŒ…å«: {required_cols}")
        return False
    # æ£€æŸ¥æ•°å€¼
    try:
        if not pd.to_numeric(settings_df['Max HR'], errors='coerce').notnull().all():
            return False
        if not pd.to_numeric(settings_df['Rest HR'], errors='coerce').notnull().all():
            return False
    except:
        return False
    return True

def get_hr_params(date, settings_df):
    """ğŸ“… æ ¹æ®è·‘æ­¥æ—¥æœŸï¼ŒæŸ¥æ‰¾å½“æ—¶ç”Ÿæ•ˆçš„å¿ƒç‡å‚æ•°"""
    target_date = pd.to_datetime(date)
    # æ‰¾åˆ°æ‰€æœ‰ç”Ÿæ•ˆæ—¥æœŸåœ¨â€œè·‘æ­¥æ—¥æœŸä¹‹å‰â€çš„è®¾ç½®
    valid_settings = settings_df[settings_df['Date'] <= target_date]
    
    if valid_settings.empty:
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œç”¨æœ€æ—©çš„ä¸€æ¡
        return settings_df.iloc[0]['Max HR'], settings_df.iloc[0]['Rest HR']
    
    # å–æœ€åä¸€æ¡ï¼ˆä¹Ÿå°±æ˜¯ç¦»è·‘æ­¥æ—¥æœŸæœ€è¿‘çš„ä¸€æ¡è¿‡å»é…ç½®ï¼‰
    latest = valid_settings.iloc[-1]
    return latest['Max HR'], latest['Rest HR']

def main():
    print("ğŸš€ å¼€å§‹æ‰§è¡Œå‘¨æŠ¥åˆ†æ (AI Analyst)...")
    client = get_client()
    if not client: return

    try:
        sh = client.open(SHEET_NAME)
    except Exception as e:
        print(f"âŒ æ‰¾ä¸åˆ°è¡¨æ ¼ '{SHEET_NAME}': {e}")
        return

    # 1. è¯»å–è¿åŠ¨æ•°æ®
    print("ğŸ“¥ è¯»å–è¿åŠ¨æ•°æ®...")
    try:
        worksheet = sh.sheet1
        df = pd.DataFrame(worksheet.get_all_records())
        # æ¸…æ´— Activity ID åˆ—ï¼Œé˜²æ­¢ç§‘å­¦è®¡æ•°æ³•å¹²æ‰°
        if 'Activity ID' in df.columns:
             df['Activity ID'] = df['Activity ID'].astype(str)
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date') # æŒ‰æ—¶é—´æ­£åºæ’åˆ—
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
        return

    # 2. è¯»å–å¿ƒç‡è®¾ç½®
    print("âš™ï¸ è¯»å–ç”¨æˆ·é…ç½®...")
    try:
        settings_ws = sh.worksheet('Settings')
        settings_df = pd.DataFrame(settings_ws.get_all_records())
        settings_df['Date'] = pd.to_datetime(settings_df['Date'], errors='coerce')
        settings_df = settings_df.dropna(subset=['Date']).sort_values('Date')
        
        if not validate_settings(settings_df):
            raise ValueError("æ ¡éªŒæœªé€šè¿‡")
    except Exception as e:
        print(f"âš ï¸ è¯»å– Settings å¤±è´¥ ({e})ï¼Œä½¿ç”¨é»˜è®¤å€¼ (Max:185, Rest:55)")
        settings_df = pd.DataFrame({'Date': [pd.Timestamp('2000-01-01')], 'Max HR': [185], 'Rest HR': [55]})

    # 3. è®¡ç®— TRIMP
    print("ğŸ§® è®¡ç®—æ¯ä¸€å•çš„è®­ç»ƒè´Ÿè· (TRIMP)...")
    trimp_list = []
    for _, row in df.iterrows():
        max_hr, rest_hr = get_hr_params(row['Date'], settings_df)
        
        # æ•°æ®å®¹é”™å¤„ç†
        try:
            avg_hr = pd.to_numeric(row['Avg HR'], errors='coerce')
            duration = pd.to_numeric(row['Duration (min)'], errors='coerce')
            
            if pd.isna(avg_hr) or pd.isna(duration) or duration == 0 or avg_hr == 0:
                trimp_list.append(0)
                continue
                
            hrr = (avg_hr - rest_hr) / (max_hr - rest_hr)
            hrr = max(0, min(1, hrr)) # é™åˆ¶åœ¨ 0-1
            weight = 0.64 * np.exp(1.92 * hrr) # ç”·æ€§ç³»æ•°
            trimp = duration * hrr * weight
            trimp_list.append(round(trimp, 1))
        except:
            trimp_list.append(0)
    
    df['TRIMP'] = trimp_list

    # 4. ç”Ÿæˆå‘¨æŠ¥ (æœ¬å‘¨æ¦‚è§ˆ)
    today = datetime.now()
    # é€»è¾‘ï¼šæ¯æ¬¡è¿è¡Œåˆ†æâ€œä¸Šå‘¨â€çš„æ•°æ®ï¼ˆå› ä¸ºå‘¨ä¸€æ—©ä¸Šè·‘ï¼Œçœ‹çš„æ˜¯åˆšè¿‡å»çš„ä¸€å‘¨ï¼‰
    # æˆ–è€…å¦‚æœä½ æ˜¯æ‰‹åŠ¨è§¦å‘ï¼Œå¯èƒ½æƒ³çœ‹â€œæœ€è¿‘7å¤©â€ã€‚
    # è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨ï¼šæœ€è¿‘å®Œæ•´çš„å‘¨ï¼ˆä¸Šå‘¨ä¸€åˆ°ä¸Šå‘¨æ—¥ï¼‰
    this_monday = today - timedelta(days=today.weekday())
    last_monday = this_monday - timedelta(days=7)
    
    mask = (df['Date'] >= last_monday) & (df['Date'] < this_monday)
    weekly_data = df[mask]
    
    # è®¡ç®— TSB (çŠ¶æ€) - åŸºäºé•¿æœŸæ•°æ®
    # æ„å»ºæ¯æ—¥æ—¶é—´åºåˆ—æ¥è®¡ç®—ç§»åŠ¨å¹³å‡
    daily_load = df.set_index('Date').resample('D')['TRIMP'].sum().fillna(0)
    
    # æˆªæ­¢åˆ°æ˜¨å¤©çš„ CTL å’Œ ATL
    current_ctl = daily_load.ewm(span=42, adjust=False).mean().iloc[-1]
    current_atl = daily_load.ewm(span=7, adjust=False).mean().iloc[-1]
    current_tsb = current_ctl - current_atl
    
    # å‡†å¤‡å‘¨æŠ¥è¡Œæ•°æ®
    # å¹³å‡é…é€Ÿè®¡ç®—éœ€è¦æŠŠ "5'30"" è½¬æˆç§’
    def parse_pace(p_str):
        try:
            if not isinstance(p_str, str): return 0
            mins = int(p_str.split("'")[0])
            secs = int(p_str.split("'")[1].replace('"',''))
            return mins * 60 + secs
        except:
            return 0
            
    avg_pace_sec = 0
    if len(weekly_data) > 0:
        total_sec = weekly_data['Avg Pace'].apply(parse_pace).sum()
        avg_pace_sec = total_sec / len(weekly_data)
        
    pace_fmt = f"{int(avg_pace_sec // 60)}'{int(avg_pace_sec % 60):02d}\"" if avg_pace_sec > 0 else "-"

    report_row = [
        last_monday.strftime("%Y-%m-%d"),          # Start Date
        this_monday.strftime("%Y-%m-%d"),          # End Date
        round(weekly_data['Distance (km)'].sum(), 2), # Total Dist
        len(weekly_data),                          # Runs
        pace_fmt,                                  # Avg Pace
        round(weekly_data['TRIMP'].sum()),         # Total Load
        round(current_ctl, 1),                     # Fitness
        round(current_tsb, 1),                     # Form
        "æ¢å¤" if current_tsb > 10 else ("é€‚ä¸­" if current_tsb > -10 else "ç–²åŠ³")
    ]
    
    print(f"ğŸ“Š ç”Ÿæˆå‘¨æŠ¥: {report_row}")

    # 5. å†™å…¥ Weekly_Report
    try:
        try:
            report_ws = sh.worksheet('Weekly_Report')
        except:
            print("âœ¨ æ–°å»º Weekly_Report è¡¨...")
            report_ws = sh.add_worksheet(title="Weekly_Report", rows=100, cols=20)
            report_ws.append_row(["Start Date", "End Date", "Distance (km)", "Runs", "Avg Pace", "Weekly Load", "Fitness (CTL)", "Form (TSB)", "Status"])
            
        # æ£€æŸ¥æ˜¯å¦å·²ç»å†™è¿‡è¿™ä¸€å‘¨ï¼ˆé˜²æ­¢é‡å¤å†™å…¥ï¼‰
        existing_reports = report_ws.get_all_values()
        is_duplicate = False
        for row in existing_reports:
            if len(row) > 0 and row[0] == report_row[0]:
                is_duplicate = True
                break
        
        if not is_duplicate:
            report_ws.append_row(report_row)
            print("âœ… å‘¨æŠ¥å·²å†™å…¥ Google Sheets")
        else:
            print("âš ï¸ æœ¬å‘¨å‘¨æŠ¥å·²å­˜åœ¨ï¼Œè·³è¿‡å†™å…¥")
            
    except Exception as e:
        print(f"âŒ å†™å…¥å‘¨æŠ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
