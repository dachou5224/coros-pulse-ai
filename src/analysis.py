import pandas as pd
import numpy as np
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime, timedelta
import os
import json

# --- é…ç½® ---
# ç›´æ¥å¤ç”¨ç°æœ‰çš„ Secret
JSON_KEY = os.getenv('GOOGLE_APPLICATION_CREDENTIALS_JSON')
SHEET_NAME = 'Coros_Running_Data'

def get_client():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    if not JSON_KEY:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° Google Credentials Secret")
        return None
    
    # å…¼å®¹å¤„ç†ï¼šå¦‚æœæ˜¯ JSON å­—ç¬¦ä¸²ç›´æ¥åŠ è½½
    try:
        creds_dict = json.loads(JSON_KEY)
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        return gspread.authorize(creds)
    except Exception as e:
        print(f"âŒ è®¤è¯å¤±è´¥: {e}")
        return None

def validate_settings(settings_df):
    """ğŸ›¡ï¸ æ ¡éªŒ Settings è¡¨æ ¼æ•°æ®çš„åˆæ³•æ€§"""
    required_cols = ['Date', 'Max HR', 'Rest HR']
    # æ£€æŸ¥åˆ—åæ˜¯å¦å­˜åœ¨
    if not all(col in settings_df.columns for col in required_cols):
        print(f"âŒ Settings è¡¨ç¼ºå°‘åˆ—ï¼Œå¿…é¡»åŒ…å«: {required_cols}")
        return False
    # æ£€æŸ¥æ•°å€¼
    try:
        if not pd.to_numeric(settings_df['Max HR'], errors='coerce').notnull().all():
            return False
        if not pd.to_numeric(settings_df['Rest HR'], errors='coerce').notnull().all():
            return False
    except:
        return False
    return True

def get_hr_params(date, settings_df):
    """ğŸ“… æ ¹æ®è·‘æ­¥æ—¥æœŸï¼ŒæŸ¥æ‰¾å½“æ—¶ç”Ÿæ•ˆçš„å¿ƒç‡å‚æ•°"""
    target_date = pd.to_datetime(date)
    # æ‰¾åˆ°æ‰€æœ‰ç”Ÿæ•ˆæ—¥æœŸåœ¨â€œè·‘æ­¥æ—¥æœŸä¹‹å‰â€çš„è®¾ç½®
    valid_settings = settings_df[settings_df['Date'] <= target_date]
    
    if valid_settings.empty:
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œç”¨æœ€æ—©çš„ä¸€æ¡
        return settings_df.iloc[0]['Max HR'], settings_df.iloc[0]['Rest HR']
    
    # å–æœ€åä¸€æ¡ï¼ˆä¹Ÿå°±æ˜¯ç¦»è·‘æ­¥æ—¥æœŸæœ€è¿‘çš„ä¸€æ¡è¿‡å»é…ç½®ï¼‰
    latest = valid_settings.iloc[-1]
    return latest['Max HR'], latest['Rest HR']
# ... import éƒ¨åˆ†ä¿æŒä¸å˜ ...

def calculate_run_vdot(distance_km, duration_min):
    """
    ğŸ§ª æ ¸å¿ƒç®—æ³•ï¼šä¼°ç®—å•æ¬¡è·‘æ­¥çš„ VDOT
    é€»è¾‘ï¼šå…ˆåˆ©ç”¨ Riegel å…¬å¼å°†æœ¬æ¬¡è¡¨ç°å½’ä¸€åŒ–ä¸º "5km ç­‰æ•ˆæˆç»©"ï¼Œ
    å†åˆ©ç”¨ Daniels è¿‘ä¼¼å…¬å¼è®¡ç®— VDOTã€‚
    """
    # 1. è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼šè·ç¦»å¤ªçŸ­æˆ–å¤ªé•¿éƒ½ä¸å‡†ï¼Œé…é€Ÿå¤ªæ…¢ä¹Ÿä¸ç®—
    if distance_km < 3 or duration_min <= 0: return 0
    
    # 2. Riegel å…¬å¼å½’ä¸€åŒ–åˆ° 5km (é¢„æµ‹å°½åŠ›è·‘ 5km çš„ç”¨æ—¶)
    # T2 = T1 * (D2 / D1)^1.06
    # è¿™é‡Œçš„å‡è®¾æ˜¯ï¼šå¦‚æœä½ è¿™æ¬¡è·‘å¾—å¾ˆå¿«ï¼ŒRiegel ä¼šé¢„æµ‹å‡ºä¸€ä¸ªå¾ˆå¿«çš„ 5k
    # å¦‚æœä½ æ˜¯æ…¢è·‘ï¼Œé¢„æµ‹å‡ºçš„ 5k ä¹Ÿä¼šå¾ˆæ…¢ (VDOT å°±ä½) â€”â€” è¿™æ²¡å…³ç³»ï¼Œæˆ‘ä»¬åé¢åªå–æœ€å¤§å€¼
    predicted_5k_min = duration_min * (5 / distance_km) ** 1.06
    
    # 3. è®¡ç®— VDOT (åŸºäº 5km æˆç»©çš„å›å½’å…¬å¼)
    # é€Ÿåº¦ (ç±³/åˆ†)
    v = 5000 / predicted_5k_min
    
    # ä¸¹å°¼å°”æ–¯æ°§æ°”æˆæœ¬å…¬å¼ (Oxygen Cost)
    # VDOT ~= VO2max / drop_off_percent
    # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªé«˜ç²¾åº¦çš„æ‹Ÿåˆå…¬å¼ç›´æ¥ç®— VDOT
    # æ¥æºï¼šRunning formulas regression
    vdot = -4.6 + 0.182258 * v + 0.000104 * v**2
    
    return round(vdot, 1)

def get_current_vdot(df, end_date, window_days=42):
    """
    ğŸ“… è·å–æˆªæ­¢åˆ° end_date çš„â€˜å½“å‰è·‘åŠ›â€™
    é€»è¾‘ï¼šå›æº¯è¿‡å» window_days (é»˜è®¤6å‘¨) å†…æ‰€æœ‰è·‘æ­¥è®°å½•ï¼Œ
    å–å…¶ä¸­è®¡ç®—å‡ºçš„ã€æœ€å¤§ VDOT å€¼ã€‘ã€‚
    """
    start_date = end_date - timedelta(days=window_days)
    
    # ç­›é€‰æ—¶é—´çª—å£å†…çš„æ•°æ®
    mask = (df['Date'] >= start_date) & (df['Date'] <= end_date)
    window_df = df[mask]
    
    if window_df.empty:
        return 0
    
    # è®¡ç®—æ¯ä¸€å•çš„ VDOT
    vdot_values = []
    for _, row in window_df.iterrows():
        # å®¹é”™å¤„ç†
        try:
            d = float(row['Distance (km)'])
            t = float(row['Duration (min)'])
            v = calculate_run_vdot(d, t)
            if v > 0: vdot_values.append(v)
        except: continue
        
    if not vdot_values: return 0
    
    # å…³é”®ï¼šå–æœ€å¤§å€¼ (ä»£è¡¨ä½ çš„æ½œèƒ½ä¸Šé™)
    return max(vdot_values)
def parse_pace_to_speed(pace_str):
    """è¾…åŠ©ï¼šæŠŠ 5'30" è½¬æˆ é€Ÿåº¦å€¼ (km/h æˆ– m/s å‡å¯ï¼Œè¿™é‡Œç”¨ m/s)"""
    try:
        if not isinstance(pace_str, str): return 0
        mins = int(pace_str.split("'")[0])
        secs = int(pace_str.split("'")[1].replace('"',''))
        total_sec = mins * 60 + secs
        if total_sec == 0: return 0
        return 1000 / total_sec # m/s
    except:
        return 0

def calculate_decoupling(splits_json):
    """
    ğŸ§ª æ ¸å¿ƒç®—æ³•ï¼šè®¡ç®—æœ‰æ°§è„±é’©ç‡ (Pw:HR)
    """
    try:
        splits = json.loads(splits_json)
        # åªæœ‰åˆ†æ®µæ•°é‡è¶³å¤Ÿï¼ˆè‡³å°‘4kmï¼‰æ‰è®¡ç®—ï¼Œå¤ªçŸ­æ²¡æ„ä¹‰
        if not splits or len(splits) < 4: 
            return None 
        
        # ç®€å•çš„åˆ‡åˆ†ï¼šå‰åŠç¨‹ vs ååŠç¨‹
        half_idx = len(splits) // 2
        first_half = splits[:half_idx]
        second_half = splits[half_idx:]
        
        # è®¡ç®—ä¸¤æ®µçš„å¹³å‡é€Ÿåº¦å’Œå¹³å‡å¿ƒç‡
        v1 = np.mean([parse_pace_to_speed(s['pace']) for s in first_half])
        h1 = np.mean([s['hr'] for s in first_half])
        
        v2 = np.mean([parse_pace_to_speed(s['pace']) for s in second_half])
        h2 = np.mean([s['hr'] for s in second_half])
        
        if h1 == 0 or h2 == 0: return None
        
        # æ•ˆç‡ç³»æ•° (Efficiency Factor) = Speed / HR
        ef1 = v1 / h1
        ef2 = v2 / h2
        
        # è„±é’©ç‡
        decoupling = (ef1 - ef2) / ef1 * 100
        return round(decoupling, 2)
        
    except Exception as e:
        return None
# ... main å‡½æ•° ...
def main():
    print("ğŸš€ å¼€å§‹æ‰§è¡Œå‘¨æŠ¥åˆ†æ (AI Analyst)...")
    client = get_client()
    if not client: return

    try:
        sh = client.open(SHEET_NAME)
    except Exception as e:
        print(f"âŒ æ‰¾ä¸åˆ°è¡¨æ ¼ '{SHEET_NAME}': {e}")
        return

    # 1. è¯»å–è¿åŠ¨æ•°æ®
    print("ğŸ“¥ è¯»å–è¿åŠ¨æ•°æ®...")
    try:
        worksheet = sh.sheet1
        df = pd.DataFrame(worksheet.get_all_records())
        # æ¸…æ´— Activity ID åˆ—ï¼Œé˜²æ­¢ç§‘å­¦è®¡æ•°æ³•å¹²æ‰°
        if 'Activity ID' in df.columns:
             df['Activity ID'] = df['Activity ID'].astype(str)
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date') # æŒ‰æ—¶é—´æ­£åºæ’åˆ—
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
        return

    # 2. è¯»å–å¿ƒç‡è®¾ç½®
    print("âš™ï¸ è¯»å–ç”¨æˆ·é…ç½®...")
    try:
        settings_ws = sh.worksheet('Settings')
        settings_df = pd.DataFrame(settings_ws.get_all_records())
        settings_df['Date'] = pd.to_datetime(settings_df['Date'], errors='coerce')
        settings_df = settings_df.dropna(subset=['Date']).sort_values('Date')
        
        if not validate_settings(settings_df):
            raise ValueError("æ ¡éªŒæœªé€šè¿‡")
    except Exception as e:
        print(f"âš ï¸ è¯»å– Settings å¤±è´¥ ({e})ï¼Œä½¿ç”¨é»˜è®¤å€¼ (Max:185, Rest:55)")
        settings_df = pd.DataFrame({'Date': [pd.Timestamp('2000-01-01')], 'Max HR': [185], 'Rest HR': [55]})

    # 3. è®¡ç®— TRIMP
    print("ğŸ§® è®¡ç®—æ¯ä¸€å•çš„è®­ç»ƒè´Ÿè· (TRIMP)...")
    trimp_list = []
    for _, row in df.iterrows():
        max_hr, rest_hr = get_hr_params(row['Date'], settings_df)
        
        # æ•°æ®å®¹é”™å¤„ç†
        try:
            avg_hr = pd.to_numeric(row['Avg HR'], errors='coerce')
            duration = pd.to_numeric(row['Duration (min)'], errors='coerce')
            
            if pd.isna(avg_hr) or pd.isna(duration) or duration == 0 or avg_hr == 0:
                trimp_list.append(0)
                continue
                
            hrr = (avg_hr - rest_hr) / (max_hr - rest_hr)
            hrr = max(0, min(1, hrr)) # é™åˆ¶åœ¨ 0-1
            weight = 0.64 * np.exp(1.92 * hrr) # ç”·æ€§ç³»æ•°
            trimp = duration * hrr * weight
            trimp_list.append(round(trimp, 1))
        except:
            trimp_list.append(0)
    
    df['TRIMP'] = trimp_list

    # 4. ç”Ÿæˆå‘¨æŠ¥ (æœ¬å‘¨æ¦‚è§ˆ)
    today = datetime.now()
    # é€»è¾‘ï¼šæ¯æ¬¡è¿è¡Œåˆ†æâ€œä¸Šå‘¨â€çš„æ•°æ®ï¼ˆå› ä¸ºå‘¨ä¸€æ—©ä¸Šè·‘ï¼Œçœ‹çš„æ˜¯åˆšè¿‡å»çš„ä¸€å‘¨ï¼‰
    # æˆ–è€…å¦‚æœä½ æ˜¯æ‰‹åŠ¨è§¦å‘ï¼Œå¯èƒ½æƒ³çœ‹â€œæœ€è¿‘7å¤©â€ã€‚
    # è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨ï¼šæœ€è¿‘å®Œæ•´çš„å‘¨ï¼ˆä¸Šå‘¨ä¸€åˆ°ä¸Šå‘¨æ—¥ï¼‰
    this_monday = today - timedelta(days=today.weekday())
    last_monday = this_monday - timedelta(days=7)
    
    mask = (df['Date'] >= last_monday) & (df['Date'] < this_monday)
    weekly_data = df[mask]
    
    # è®¡ç®— TSB (çŠ¶æ€) - åŸºäºé•¿æœŸæ•°æ®
    # æ„å»ºæ¯æ—¥æ—¶é—´åºåˆ—æ¥è®¡ç®—ç§»åŠ¨å¹³å‡
    daily_load = df.set_index('Date').resample('D')['TRIMP'].sum().fillna(0)
    
    # æˆªæ­¢åˆ°æ˜¨å¤©çš„ CTL å’Œ ATL
    current_ctl = daily_load.ewm(span=42, adjust=False).mean().iloc[-1]
    current_atl = daily_load.ewm(span=7, adjust=False).mean().iloc[-1]
    current_tsb = current_ctl - current_atl
    
    # ğŸ†• è®¡ç®—æœ¬å‘¨ç”Ÿæ•ˆçš„ VDOT (åŸºäºè¿‡å» 6 å‘¨çš„æœ€ä½³è¡¨ç°)
    # æ³¨æ„ï¼šæˆ‘ä»¬ç”¨ last_monday + 7å¤© (å³æœ¬å‘¨ç»“æŸæ—¶) ä½œä¸ºåŸºå‡†ç‚¹
    current_vdot = get_current_vdot(df, this_monday, window_days=42)
    
    # ğŸ†• å¯»æ‰¾æœ¬å‘¨çš„â€œé•¿è·ç¦»è·‘â€ (LSD) å¹¶è®¡ç®—è„±é’©ç‡
    # é€»è¾‘ï¼šæ‰¾åˆ°æœ¬å‘¨è·ç¦»æœ€é•¿çš„ä¸€æ¡è®°å½•
    longest_run_decoupling = "-"
    try:
        if not weekly_data.empty:
            # æ‰¾åˆ°è·ç¦»æœ€å¤§çš„é‚£ä¸€è¡Œ
            longest_run = weekly_data.loc[weekly_data['Duration (min)'].idxmax()]
            
            # å¦‚æœè¿™å•é•¿è·ç¦» > 30åˆ†é’Ÿ (å¤ªçŸ­ç®—è„±é’©æ²¡æ„ä¹‰)
            if pd.to_numeric(longest_run['Duration (min)']) > 30:
                dc = calculate_decoupling(longest_run['Splits (JSON)'])
                if dc is not None:
                    longest_run_decoupling = f"{dc}%"
    except Exception as e:
        print(f"âš ï¸ è®¡ç®—è„±é’©ç‡å‡ºé”™: {e}")
        
    # å‡†å¤‡å‘¨æŠ¥è¡Œæ•°æ®
    # å¹³å‡é…é€Ÿè®¡ç®—éœ€è¦æŠŠ "5'30"" è½¬æˆç§’
    def parse_pace(p_str):
        try:
            if not isinstance(p_str, str): return 0
            mins = int(p_str.split("'")[0])
            secs = int(p_str.split("'")[1].replace('"',''))
            return mins * 60 + secs
        except:
            return 0
            
    avg_pace_sec = 0
    if len(weekly_data) > 0:
        total_sec = weekly_data['Avg Pace'].apply(parse_pace).sum()
        avg_pace_sec = total_sec / len(weekly_data)
        
    pace_fmt = f"{int(avg_pace_sec // 60)}'{int(avg_pace_sec % 60):02d}\"" if avg_pace_sec > 0 else "-"

    report_row = [
        last_monday.strftime("%Y-%m-%d"),          # Start Date
        this_monday.strftime("%Y-%m-%d"),          # End Date
        round(weekly_data['Distance (km)'].sum(), 2), # Total Dist
        len(weekly_data),                          # Runs
        pace_fmt,                                  # Avg Pace
        round(weekly_data['TRIMP'].sum()),         # Total Load
        round(current_ctl, 1),                     # Fitness
        round(current_tsb, 1),                     # Form
        current_vdot,
        longest_run_decoupling, # <--- æ–°å¢ï¼šé•¿è·ç¦»è„±é’©ç‡
        "æ¢å¤" if current_tsb > 10 else ("é€‚ä¸­" if current_tsb > -10 else "ç–²åŠ³")
    ]
    
    print(f"ğŸ“Š ç”Ÿæˆå‘¨æŠ¥: {report_row}")

    # 5. å†™å…¥ Weekly_Report
    try:
        try:
            report_ws = sh.worksheet('Weekly_Report')
        except:
            print("âœ¨ æ–°å»º Weekly_Report è¡¨...")
           report_ws = sh.add_worksheet(title="Weekly_Report", rows=100, cols=20)
            report_ws.append_row(["Start Date", "End Date", "Distance (km)", "Runs", "Avg Pace", "Weekly Load", "Fitness (CTL)", "Form (TSB)", "VDOT", "LSD Decouple", "Status"]) # <--- åŠ äº† VDOT
            
        # æ£€æŸ¥æ˜¯å¦å·²ç»å†™è¿‡è¿™ä¸€å‘¨ï¼ˆé˜²æ­¢é‡å¤å†™å…¥ï¼‰
        existing_reports = report_ws.get_all_values()
        is_duplicate = False
        for row in existing_reports:
            if len(row) > 0 and row[0] == report_row[0]:
                is_duplicate = True
                break
        
        if not is_duplicate:
            report_ws.append_row(report_row)
            print("âœ… å‘¨æŠ¥å·²å†™å…¥ Google Sheets")
        else:
            print("âš ï¸ æœ¬å‘¨å‘¨æŠ¥å·²å­˜åœ¨ï¼Œè·³è¿‡å†™å…¥")
            
    except Exception as e:
        print(f"âŒ å†™å…¥å‘¨æŠ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
